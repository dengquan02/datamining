{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236e2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cea231",
   "metadata": {},
   "outputs": [],
   "source": [
    "lonStep_1m = 0.0000105\n",
    "latStep_1m = 0.0000090201\n",
    "# 划分栅格\n",
    "class RoadGrid:\n",
    "    def __init__(self, label, grid_size):\n",
    "        length = grid_size*latStep_1m\n",
    "        width = grid_size*lonStep_1m\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        def orginal_plot(label):\n",
    "            tr = np.max(label,axis=0)\n",
    "            tr[0]+=25*lonStep_1m\n",
    "            tr[1]+=25*latStep_1m\n",
    "            # plot(label[:,0], label[:,1], 'b,')\n",
    "            bl = np.min(label,axis=0)\n",
    "            bl[0]-=25*lonStep_1m\n",
    "            bl[1]-=25*latStep_1m\n",
    "\n",
    "            # width = (tr[1]-bl[1])/100\n",
    "            # wnum =int(np.ceil((tr[1]-bl[1])/length))\n",
    "            # for j in range(wnum):\n",
    "                # hlines(y = bl[1]+length*j, xmin = bl[0], xmax = tr[0], color = 'red')\n",
    "\n",
    "            # lnum = int(np.ceil((tr[0]-bl[0])/width))\n",
    "            # for j in range(lnum):\n",
    "                # vlines(x = bl[0]+width*j, ymin = bl[1], ymax = tr[1], color = 'red')\n",
    "            return bl[0], tr[0], bl[1], tr[1]\n",
    "\n",
    "        xl,xr,yb,yt = orginal_plot(label)\n",
    "        self.xl = xl\n",
    "        self.xr = xr\n",
    "        self.yb = yb\n",
    "        self.yt = yt\n",
    "        gridSet = set()\n",
    "        grid_dict = {}\n",
    "        self.grid_dict = {}\n",
    "        for pos in label:\n",
    "            lon = pos[0]\n",
    "            lat = pos[1]\n",
    "\n",
    "            m = int((lon-xl)/width)\n",
    "            n = int((lat-yb)/length)\n",
    "            if (m,n) not in grid_dict:\n",
    "                grid_dict[(m,n)] = []\n",
    "            grid_dict[(m,n)].append((lon, lat))\n",
    "            gridSet.add((m,n))\n",
    "        # print len(gridSet)\n",
    "        gridlist = list(gridSet)\n",
    "\n",
    "            \n",
    "            \n",
    "        grid_center = [tuple(np.mean(np.array(grid_dict[grid]),axis=0)) for grid in gridlist]\n",
    "\n",
    "\n",
    "        # for gs in gridSet:\n",
    "            # xlon = xl+gs[0]*width\n",
    "            # ylat = yb+gs[1]*length\n",
    "            # bar(xlon,length,width,ylat,color='#7ED321')\n",
    "        self.gridlist = gridlist\n",
    "\n",
    "        self.grids = [(xl+i[0]*width,yb + i[1]*length) for i in grid_dict.keys()] # 左下角的点\n",
    "        self.grid_center = grid_center\n",
    "        self.n_grid = len(self.grid_center)\n",
    "        self.grid_dict = grid_dict\n",
    "\n",
    "    def transform(self, label, sparse=True):\n",
    "        def one_hot(idx, n):\n",
    "            a = [0] * n\n",
    "            a[idx] = 1\n",
    "            return a\n",
    "        grid_pos = [self.gridlist.index((int((i[0]-self.xl)/self.width),int((i[1]-self.yb)/self.length))) for i in label]\n",
    "        if sparse:\n",
    "            grid_pos = np.array([one_hot(x, len(self.gridlist)) for x in grid_pos], dtype=np.int32)\n",
    "        return grid_pos\n",
    "    \n",
    "def rad(d):\n",
    "    return d * math.pi / 180.0\n",
    "\n",
    "# 地理坐标系：为球面坐标。 参考平面地是椭球面，坐标单位：经纬度；\n",
    "# 投影坐标系：为平面坐标。参考平面地是水平面，坐标单位：米、千米等；\n",
    "# 地理坐标转换到投影坐标的过程可理解为投影。（投影：将不规则的地球曲面转换为平面）\n",
    "\n",
    "# 目前国内主要有三种地理坐标系\n",
    "# 1、WGS84坐标系：即地球坐标系（World Geodetic System），国际上通用的坐标系。\n",
    "# 设备包含的GPS芯片或者北斗芯片获取的经纬度一般都是为WGS84地理坐标系，目前谷歌地图采用的是WGS84坐标系（中国范围除外）。\n",
    "# 2、GCJ02坐标系：即火星坐标系，国测局坐标系。是由中国国家测绘局制定。由WGS84坐标系经加密后的坐标系。谷歌中国和搜搜中国采用。\n",
    "# 3、BD09坐标系：百度坐标系，GCJ02坐标系经加密后的坐标系。\n",
    "\n",
    "# 投影：墨卡托投影、高斯-克吕格 (Gauss-Krüger) 投影\n",
    "# 感兴趣的同学可以在https://desktop.arcgis.com/zh-cn/arcmap/10.3/guide-books/map-projections/list-of-supported-map-projections.htm深入了解\n",
    "\n",
    "# gps两点间距离（单位为米）\n",
    "def distance(true_pt, pred_pt):\n",
    "    lat1 = float(true_pt[1])\n",
    "    lng1 = float(true_pt[0])\n",
    "    lat2 = float(pred_pt[1])\n",
    "    lng2 = float(pred_pt[0])\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    s = 2 * math.asin(math.sqrt(math.pow(math.sin(a/2),2) +\n",
    "    math.cos(radLat1)*math.cos(radLat2)*math.pow(math.sin(b/2),2)))\n",
    "    s = s * 6378.137\n",
    "    s = round(s * 10000) / 10\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e951f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "# sf = pd.read_csv(\"ft_ns.csv\").head(500)\n",
    "sf = pd.read_csv(\"../Trajectory data/2G_data.csv\", encoding = 'gb2312').head(500)\n",
    "#sf = sf.append(_)\n",
    "#匹配工参\n",
    "# sf_eng = pd.read_csv(\"ft_ns_bs_fix.csv\")\n",
    "sf_eng = pd.read_csv(\"../Trajectory data/2G_gongcan.csv\", encoding = 'gb2312')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006479d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8f53a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mnc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     sf \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43msf_eng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnc_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlac_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcid_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m sf \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m999\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#过滤无用数据\u001b[39;00m\n",
      "File \u001b[1;32mD:\\CONDA\\envs\\data_mining\\lib\\site-packages\\pandas\\core\\frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9320\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9321\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   9322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9335\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9348\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9349\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\CONDA\\envs\\data_mining\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mD:\\CONDA\\envs\\data_mining\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m--> 700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mD:\\CONDA\\envs\\data_mining\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1097\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_rkey(rk):\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1097\u001b[0m         right_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m         right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mD:\\CONDA\\envs\\data_mining\\lib\\site-packages\\pandas\\core\\generic.py:1848\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1848\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mnc'"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    sf = sf.merge(sf_eng, left_on = ['mnc_%d'% i, 'lac_%d' % i, 'cid_%d' % i,], \n",
    "                  right_on = ['mnc','lac','cid'], how = 'left', suffixes = ('', '%d' % i))\n",
    "sf = sf.fillna(-999)\n",
    "#过滤无用数据\n",
    "for i in range(1, 9):\n",
    "    sf = sf[(sf['mcc_%d' % i] == 460) | (sf['mcc_%d' % i] == -1)]\n",
    "sf = sf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fcc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cloumns_name = [ 'mnc_1','lac_1', 'cid_1','ss_1',\n",
    "                        'mnc_2','lac_2', 'cid_2','ss_2',\n",
    "                        'mnc_3','lac_3', 'cid_3','ss_3',\n",
    "                        'mnc_4','lac_4', 'cid_4','ss_4',\n",
    "                        'mnc_5','lac_5', 'cid_5','ss_5',\n",
    "                        'mnc_6','lac_6', 'cid_6','ss_6',\n",
    "                        'mnc_7','lac_7', 'cid_7','ss_7',\n",
    "                        'mnc_8','lac_8', 'cid_8','ss_8',\n",
    "                        'lon','lat','lon2','lat2',\n",
    "                        'lon3','lat3','lon4','lat4',\n",
    "                        'lon5','lat5','lon6','lat6',\n",
    "                        'lon7','lat7','lon8','lat8',]\n",
    "grid_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31443e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.15 575.699 1868.3\n"
     ]
    }
   ],
   "source": [
    "# 训练及测试\n",
    "grider = RoadGrid(sf[['x', 'y']].values, grid_size)\n",
    "sf['grid_id'] = grider.transform(sf[['x', 'y']].values, False)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X,Xe,Y,Ye = train_test_split(sf, sf[['x','y','grid_id']], test_size=0.2, random_state=200)\n",
    "regr = RandomForestClassifier(n_estimators=10).fit(X[feature_cloumns_name], Y['grid_id'])\n",
    "pred= regr.predict(Xe[feature_cloumns_name])\n",
    "pred_loc = np.array([grider.grid_center[idx] for idx in pred])\n",
    "err = [distance(p,t) for p, t in zip(pred_loc, Ye[['x','y']].values)]\n",
    "print (np.median(err), np.mean(err), err[int(len(err)*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73dcd811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.5 480.5299999999999 1319.8\n",
      "164.5 493.689 1487.1\n",
      "164.5 481.87700000000007 1359.9\n",
      "148.5 582.075 1487.1\n",
      "168.35 572.6340000000001 1524.9\n",
      "163.6 524.8690000000001 1218.6\n",
      "164.5 622.691 1863.8\n",
      "135.35000000000002 479.18699999999995 1218.6\n",
      "171.45 642.134 1711.6\n",
      "164.5 564.322 1408.9\n",
      "160.775 544.4008000000001 1460.03\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证\n",
    "grider = RoadGrid(sf[['x', 'y']].values, grid_size)\n",
    "sf['grid_id'] = grider.transform(sf[['x', 'y']].values, False)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "med, mea, nin = [], [], []\n",
    "# 10-fold cross validation\n",
    "for i in range(10):\n",
    "    X,Xe,Y,Ye = train_test_split(sf, sf[['x','y','grid_id']], test_size=0.2, random_state=200)\n",
    "    regr = RandomForestClassifier().fit(X[feature_cloumns_name], Y['grid_id'])\n",
    "    pred= regr.predict(Xe[feature_cloumns_name])\n",
    "    pred_loc = np.array([grider.grid_center[idx] for idx in pred])\n",
    "    err = [distance(p,t) for p, t in zip(pred_loc, Ye[['x','y']].values)]\n",
    "    err = sorted(err)\n",
    "    med.append(np.median(err))\n",
    "    mea.append(np.mean(err))\n",
    "    nin.append(err[int(len(err)*0.9)])\n",
    "    print (np.median(err), np.mean(err), err[int(len(err)*0.9)])\n",
    "print (np.mean(med), np.mean(mea), np.mean(nin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638fa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
