{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- 机器学习在定位上的应用：https://cloud.tencent.com/developer/news/701639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle  \n",
    "\n",
    "# 加载数据集\n",
    "def load_data(data_path, shuff=True):\n",
    "    data = pd.read_csv(data_path)\n",
    "    data = data.fillna(-1)  # Nan值填充\n",
    "#     print(data.iloc[1000])\n",
    "    if shuff:   # 将数据集打乱\n",
    "        data = shuffle(data)\n",
    "#     print(data.iloc[1000])\n",
    "    # 构建数据集和标签\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for index, row in data.iterrows():\n",
    "    # print(row) # 输出每行的索引值\n",
    "        matrix = []  # 7 * 4\n",
    "        for i in range(7):\n",
    "            matrix.append([i+1,\n",
    "                           row['AsuLevel_' + str(i+1)],\n",
    "                           row['SignalLevel_' + str(i+1)],\n",
    "                           row['Dbm_' + str(i+1)]]) # 新数据集中不存在RSSI，使用Dbm(代功率的绝对值)\n",
    "        # print(matrix)\n",
    "        samples.append(matrix)\n",
    "        labels.append([row['Longitude'], row['Latitude']])\n",
    "    return np.array(samples), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  64.   4. -76.]\n",
      " [  2.  66.   4. -74.]\n",
      " [  3.  51.   4. -89.]\n",
      " [  4.  51.   4. -89.]\n",
      " [  5.  -1.  -1.  -1.]\n",
      " [  6.  -1.  -1.  -1.]\n",
      " [  7.  -1.  -1.  -1.]] [121.4960706   31.28294881]\n"
     ]
    }
   ],
   "source": [
    "path = r\"./siping_4g.csv\"\n",
    "samples, labels = load_data(path)\n",
    "print(samples[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3479, 7, 4)\n",
      "(3479, 2)\n"
     ]
    }
   ],
   "source": [
    "print(samples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据变形： (3479, 7, 4)---》 (3479, 7, 4，1)\n",
    "samples = samples.reshape(-1, 7,4,1) # -1自动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2783\n",
      "2783\n",
      "[[[   1.]\n",
      "  [  63.]\n",
      "  [   4.]\n",
      "  [ -77.]]\n",
      "\n",
      " [[   2.]\n",
      "  [  45.]\n",
      "  [   4.]\n",
      "  [ -95.]]\n",
      "\n",
      " [[   3.]\n",
      "  [  38.]\n",
      "  [   3.]\n",
      "  [-102.]]\n",
      "\n",
      " [[   4.]\n",
      "  [  42.]\n",
      "  [   3.]\n",
      "  [ -98.]]\n",
      "\n",
      " [[   5.]\n",
      "  [  -1.]\n",
      "  [  -1.]\n",
      "  [  -1.]]\n",
      "\n",
      " [[   6.]\n",
      "  [  -1.]\n",
      "  [  -1.]\n",
      "  [  -1.]]\n",
      "\n",
      " [[   7.]\n",
      "  [  -1.]\n",
      "  [  -1.]\n",
      "  [  -1.]]]\n",
      "[121.49834     31.28468888]\n",
      "(2783, 2)\n",
      "(2783, 7, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(samples, labels, test_size=0.2)  #划分训练数据、训练标签、验证数据、验证标签\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "# print(x_test[100])\n",
    "# print(y_test[100])\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试在竞争对手中的前10%，只需要多走一步\n",
    "\n",
    "from keras.utils import np_utils # keras中numpy工具包\n",
    "from keras.models import Sequential\n",
    "# 二维卷积 数据池化  数据扁平化(reshape)\n",
    "from keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "# 优化器\n",
    "# from keras.optimizers import Adam\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "# # 换为one-hot格式\n",
    "# y_train = np_utils.to_categorical(y_train, num_classes=122)\n",
    "# y_test = np_utils.to_categorical(y_test, num_classes=122)\n",
    "# print(y_train[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002284F307730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002284F307730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function distance at 0x000002284EBC0E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function distance at 0x000002284EBC0E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 2), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17512\\3022542554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 训练模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 评估模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# loss, accuracy = model.evaluate(x_test, y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\AI-learning\\1-hello\\ai\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17512\\2414162601.py\u001b[0m in \u001b[0;36mdistance\u001b[1;34m(true_pt, pred_pt)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mradLat1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mradLat2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlng1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlng2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     s = 2 * math.asin(math.sqrt(math.pow(math.sin(a/2),2) +\n\u001b[0m\u001b[0;32m     85\u001b[0m     math.cos(radLat1)*math.cos(radLat2)*math.pow(math.sin(b/2),2)))\n\u001b[0;32m     86\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m6378.137\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not Tensor"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=100,validation_split=0.2, verbose=0)\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print('train loss: ', loss)\n",
    "print('train accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_120 (Conv2D)         (None, 7, 4, 32)          320       \n",
      "                                                                 \n",
      " max_pooling2d_120 (MaxPooli  (None, 4, 2, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 4, 2, 64)          51264     \n",
      "                                                                 \n",
      " max_pooling2d_121 (MaxPooli  (None, 2, 1, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 1024)              132096    \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,705\n",
      "Trainable params: 184,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002284F0CB840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002284F0CB840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function distance at 0x0000022852379840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function distance at 0x0000022852379840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "----------- <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"sub:0\", shape=(2,), dtype=float32)\n",
      "----------- <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"sub:0\", shape=(2,), dtype=float32)\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 46.1573 - accuracy: 0.0000e+00 - distance: 3928961.5000WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002285165B950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002285165B950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "----------- <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"sub:0\", shape=(2,), dtype=float32)\n",
      "35/35 [==============================] - 1s 13ms/step - loss: 45.8882 - accuracy: 0.0000e+00 - distance: 3910262.5000 - val_loss: 38.7978 - val_accuracy: 0.0000e+00 - val_distance: 3654475.0000\n",
      "Epoch 2/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 40.2547 - accuracy: 0.0000e+00 - distance: 3717158.2500 - val_loss: 39.5439 - val_accuracy: 0.0000e+00 - val_distance: 3675678.2500\n",
      "Epoch 3/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 40.0149 - accuracy: 0.0000e+00 - distance: 3684711.2500 - val_loss: 39.7125 - val_accuracy: 0.0000e+00 - val_distance: 3659318.5000\n",
      "Epoch 4/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 40.0698 - accuracy: 0.0000e+00 - distance: 3725157.7500 - val_loss: 38.9522 - val_accuracy: 0.0000e+00 - val_distance: 3651381.7500\n",
      "Epoch 5/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.8276 - accuracy: 0.0000e+00 - distance: 3711969.2500 - val_loss: 37.6164 - val_accuracy: 0.0000e+00 - val_distance: 3560603.5000\n",
      "Epoch 6/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.9260 - accuracy: 0.0000e+00 - distance: 3671478.7500 - val_loss: 37.7962 - val_accuracy: 0.0000e+00 - val_distance: 3579719.0000\n",
      "Epoch 7/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5931 - accuracy: 0.0000e+00 - distance: 3667763.2500 - val_loss: 37.8954 - val_accuracy: 0.0000e+00 - val_distance: 3580906.5000\n",
      "Epoch 8/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.7167 - accuracy: 0.0000e+00 - distance: 3664835.7500 - val_loss: 39.3495 - val_accuracy: 0.0000e+00 - val_distance: 3634589.0000\n",
      "Epoch 9/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 39.7209 - accuracy: 0.0000e+00 - distance: 3705464.7500 - val_loss: 38.4353 - val_accuracy: 0.0000e+00 - val_distance: 3617569.5000\n",
      "Epoch 10/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5160 - accuracy: 0.0000e+00 - distance: 3673748.0000 - val_loss: 37.6383 - val_accuracy: 0.0000e+00 - val_distance: 3564952.5000\n",
      "Epoch 11/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4916 - accuracy: 0.0000e+00 - distance: 3662928.0000 - val_loss: 38.6095 - val_accuracy: 0.0000e+00 - val_distance: 3613032.5000\n",
      "Epoch 12/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4493 - accuracy: 0.0000e+00 - distance: 3659870.5000 - val_loss: 38.5502 - val_accuracy: 0.0000e+00 - val_distance: 3606454.0000\n",
      "Epoch 13/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.7450 - accuracy: 0.0000e+00 - distance: 3682367.2500 - val_loss: 40.6920 - val_accuracy: 0.0000e+00 - val_distance: 3704501.2500\n",
      "Epoch 14/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.6207 - accuracy: 0.0000e+00 - distance: 3655785.5000 - val_loss: 37.9621 - val_accuracy: 0.0000e+00 - val_distance: 3598379.2500\n",
      "Epoch 15/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4045 - accuracy: 0.0000e+00 - distance: 3676872.5000 - val_loss: 38.2792 - val_accuracy: 0.0000e+00 - val_distance: 3601919.2500\n",
      "Epoch 16/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4805 - accuracy: 0.0000e+00 - distance: 3636081.5000 - val_loss: 37.6220 - val_accuracy: 0.0000e+00 - val_distance: 3553638.2500\n",
      "Epoch 17/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.6006 - accuracy: 0.0000e+00 - distance: 3684221.5000 - val_loss: 38.9503 - val_accuracy: 0.0000e+00 - val_distance: 3619949.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.6542 - accuracy: 0.0000e+00 - distance: 3653044.0000 - val_loss: 38.7302 - val_accuracy: 0.0000e+00 - val_distance: 3614826.2500\n",
      "Epoch 19/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4228 - accuracy: 0.0000e+00 - distance: 3663456.0000 - val_loss: 37.5171 - val_accuracy: 0.0000e+00 - val_distance: 3567292.7500\n",
      "Epoch 20/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5577 - accuracy: 0.0000e+00 - distance: 3677534.5000 - val_loss: 38.1604 - val_accuracy: 0.0000e+00 - val_distance: 3595759.0000\n",
      "Epoch 21/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5304 - accuracy: 0.0000e+00 - distance: 3684555.7500 - val_loss: 38.3629 - val_accuracy: 0.0000e+00 - val_distance: 3603768.5000\n",
      "Epoch 22/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.3979 - accuracy: 0.0000e+00 - distance: 3643628.0000 - val_loss: 38.0930 - val_accuracy: 0.0000e+00 - val_distance: 3589078.7500\n",
      "Epoch 23/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5501 - accuracy: 0.0000e+00 - distance: 3652586.0000 - val_loss: 37.6094 - val_accuracy: 0.0000e+00 - val_distance: 3575106.7500\n",
      "Epoch 24/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.3771 - accuracy: 0.0000e+00 - distance: 3648811.7500 - val_loss: 37.8765 - val_accuracy: 0.0000e+00 - val_distance: 3576419.7500\n",
      "Epoch 25/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4131 - accuracy: 0.0000e+00 - distance: 3679969.2500 - val_loss: 37.6652 - val_accuracy: 0.0000e+00 - val_distance: 3566389.7500\n",
      "Epoch 26/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.6558 - accuracy: 0.0000e+00 - distance: 3644375.2500 - val_loss: 38.4647 - val_accuracy: 0.0000e+00 - val_distance: 3605166.0000\n",
      "Epoch 27/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.3895 - accuracy: 0.0000e+00 - distance: 3660340.2500 - val_loss: 38.0087 - val_accuracy: 0.0000e+00 - val_distance: 3603137.0000\n",
      "Epoch 28/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.3929 - accuracy: 0.0000e+00 - distance: 3663848.2500 - val_loss: 37.7068 - val_accuracy: 0.0000e+00 - val_distance: 3572054.0000\n",
      "Epoch 29/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4454 - accuracy: 0.0000e+00 - distance: 3656071.0000 - val_loss: 39.6375 - val_accuracy: 0.0000e+00 - val_distance: 3666884.7500\n",
      "Epoch 30/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5685 - accuracy: 0.0000e+00 - distance: 3660522.2500 - val_loss: 37.8021 - val_accuracy: 0.0000e+00 - val_distance: 3562219.0000\n",
      "Epoch 31/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.3205 - accuracy: 0.0000e+00 - distance: 3658947.0000 - val_loss: 37.7776 - val_accuracy: 0.0000e+00 - val_distance: 3586319.5000\n",
      "Epoch 32/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4218 - accuracy: 0.0000e+00 - distance: 3695594.5000 - val_loss: 39.1463 - val_accuracy: 0.0000e+00 - val_distance: 3655331.2500\n",
      "Epoch 33/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4556 - accuracy: 0.0000e+00 - distance: 3666319.7500 - val_loss: 37.9413 - val_accuracy: 0.0000e+00 - val_distance: 3590062.0000\n",
      "Epoch 34/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.6021 - accuracy: 0.0000e+00 - distance: 3703056.0000 - val_loss: 39.3272 - val_accuracy: 0.0000e+00 - val_distance: 3631645.0000\n",
      "Epoch 35/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5206 - accuracy: 0.0000e+00 - distance: 3634384.7500 - val_loss: 37.6515 - val_accuracy: 0.0000e+00 - val_distance: 3573208.7500\n",
      "Epoch 36/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.3749 - accuracy: 0.0000e+00 - distance: 3648833.0000 - val_loss: 37.9967 - val_accuracy: 0.0000e+00 - val_distance: 3584273.0000\n",
      "Epoch 37/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.3467 - accuracy: 0.0000e+00 - distance: 3648007.5000 - val_loss: 37.6807 - val_accuracy: 0.0000e+00 - val_distance: 3563486.0000\n",
      "Epoch 38/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.5645 - accuracy: 0.0000e+00 - distance: 3687723.5000 - val_loss: 38.0269 - val_accuracy: 0.0000e+00 - val_distance: 3584779.0000\n",
      "Epoch 39/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.4498 - accuracy: 0.0000e+00 - distance: 3658194.7500 - val_loss: 39.3296 - val_accuracy: 0.0000e+00 - val_distance: 3639528.2500\n",
      "Epoch 40/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.5429 - accuracy: 0.0000e+00 - distance: 3666184.5000 - val_loss: 39.5237 - val_accuracy: 0.0000e+00 - val_distance: 3654071.5000\n",
      "Epoch 41/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.6144 - accuracy: 0.0000e+00 - distance: 3692436.0000 - val_loss: 39.8073 - val_accuracy: 0.0000e+00 - val_distance: 3661617.7500\n",
      "Epoch 42/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.8878 - accuracy: 0.0000e+00 - distance: 3670838.2500 - val_loss: 38.6865 - val_accuracy: 0.0000e+00 - val_distance: 3613917.2500\n",
      "Epoch 43/500\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 39.4069 - accuracy: 0.0000e+00 - distance: 3641977.0000"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义顺序模型\n",
    "model = Sequential()\n",
    "\n",
    "# 第一个卷积层\n",
    "# input_shape 输入数据的形状(平面)，只要在第一层进行设置\n",
    "\"\"\"\n",
    "    filters, 卷积核/滤波器的个数\n",
    "    kernel_size, 卷积核\n",
    "    strides=(1, 1),  步长\n",
    "    padding='valid',  填充方式\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,  激活函数\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "\"\"\"\n",
    "model.add(\n",
    "    Convolution2D(\n",
    "        input_shape = (7, 4,1),\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2 7 2\n",
    "\n",
    "# 第一个池化层:不需要输入形状 28*28 --> 28*28（same填充方式）\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "    )\n",
    ")\n",
    "\n",
    "# 第二个卷积层 池化之后 28/2  28*28--> 14*14\n",
    "model.add(Convolution2D(64,5, strides=1, padding='same', activation='relu'))\n",
    "\n",
    "# 第二个池化层  14*14\n",
    "model.add(MaxPooling2D(2,2,'same'))\n",
    "\n",
    "# 把第二个池化层的输出扁平化为一维   7*7\n",
    "model.add(Flatten()) # 7*7  --> 64*7*7\n",
    "\n",
    "# 第一个全连接层 \n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Dropout防止过拟合\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 第2个全连接层\n",
    "model.add(Dense(units=1,activation=\"relu\"))\n",
    "\n",
    "# model.add(Dense(1))\n",
    "# 定义优化器  loss 交叉熵\n",
    "# adam = Adam(lr=1e-4)\n",
    "lr = 1e-3\n",
    "adam = adam_v2.Adam(learning_rate=lr)\n",
    "# model.compile(optimizer=adam, loss='mape', metrics=['mae'])\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "def distance(true_pt, pred_pt):\n",
    "#     true_pt[0]=tf.cast(true_pt[0], tf/.float32)\n",
    "    print(\"-----------\",type(true_pt))\n",
    "#     true_pt=true_pt.to_float\n",
    "#     pred_pt=pred_pt.to_float\n",
    "    import math\n",
    "    def rad(d):\n",
    "        return d * math.pi / 180.0\n",
    "    lat1 = true_pt[1]\n",
    "    lng1 = true_pt[0]\n",
    "    lat2 = pred_pt[1]\n",
    "    lng2 = pred_pt[0]\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    print(a)\n",
    "    \n",
    "    s = 2 * tf.asin(tf.sqrt(tf.pow(tf.sin(a/2),2) +\n",
    "    tf.cos(radLat1)*tf.cos(radLat2)*tf.pow(tf.sin(b/2),2)))\n",
    "    s = s * 6378.137\n",
    "    s = round(s * 10000) / 10\n",
    "    return s\n",
    "model.compile(optimizer=adam, loss='mape', metrics=['accuracy', distance])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=500,validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "# loss, accuracy = model.evaluate(x_test, y_test)\n",
    "# print('test loss: ', loss)\n",
    "# print('test accuracy: ', accuracy)\n",
    "\n",
    "# loss, accuracy = model.evaluate(x_train, y_train)\n",
    "# print('train loss: ', loss)\n",
    "# print('train accuracy: ', accuracy)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# 数据预处理\n",
    "path = r\"../data/siping_4g.csv\"\n",
    "\n",
    "\n",
    "# 将MR数据构建为7*4的矩阵\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "matrix = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(row) # 输出每行的索引值\n",
    "    for i in range(7):\n",
    "        matrix.append([i+1,\n",
    "                       row['AsuLevel_' + str(i+1)],\n",
    "                       row['SignalLevel_' + str(i+1)],\n",
    "                       row['Dbm_' + str(i+1)]]) # 新数据集中不存在RSSI，使用Dbm(代功率的绝对值)\n",
    "    print(matrix)\n",
    "    break\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def preprocess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    # 对经纬度进行归一化的处理\n",
    "    print(data.head(1))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data[['Longitude', 'Latitude']].values)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"../data/siping_4g.csv\"\n",
    "samples, labels = load_data(path)\n",
    "print(samples[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(samples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据变形： (3479, 7, 4)---》 (3479, 7, 4，1)\n",
    "samples = samples.reshape(-1, 7,4,1) # -1自动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(samples, labels, test_size=0.2)  #划分训练数据、训练标签、验证数据、验证标签\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "# print(x_test[100])\n",
    "# print(y_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 尝试在竞争对手中的前10%，只需要多走一步\n",
    "\n",
    "from keras.utils import np_utils # keras中numpy工具包\n",
    "from keras.models import Sequential\n",
    "# 二维卷积 数据池化  数据扁平化(reshape)\n",
    "from keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "# 优化器\n",
    "# from keras.optimizers import Adam\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "# 换为one-hot格式\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=122)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=122)\n",
    "\n",
    "# 定义顺序模型\n",
    "model = Sequential()\n",
    "\n",
    "# 第一个卷积层\n",
    "# input_shape 输入数据的形状(平面)，只要在第一层进行设置\n",
    "\"\"\"\n",
    "    filters, 卷积核/滤波器的个数\n",
    "    kernel_size, 卷积核\n",
    "    strides=(1, 1),  步长\n",
    "    padding='valid',  填充方式\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,  激活函数\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "\"\"\"\n",
    "model.add(\n",
    "    Convolution2D(\n",
    "        input_shape = (7, 4,1),\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 第一个池化层:不需要输入形状 28*28 --> 28*28（same填充方式）\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "    )\n",
    ")\n",
    "\n",
    "# 第二个卷积层 池化之后 28/2  28*28--> 14*14\n",
    "model.add(Convolution2D(64,5, strides=1, padding='same', activation='relu'))\n",
    "\n",
    "# 第二个池化层  14*14\n",
    "model.add(MaxPooling2D(2,2,'same'))\n",
    "\n",
    "# 把第二个池化层的输出扁平化为一维   7*7\n",
    "model.add(Flatten()) # 7*7  --> 64*7*7\n",
    "\n",
    "# 第一个全连接层 \n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Dropout防止过拟合\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 第2个全连接层\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# 定义优化器  loss 交叉熵\n",
    "# adam = Adam(lr=1e-4)\n",
    "lr = 1e-3\n",
    "adam = adam_v2.Adam(learning_rate=lr)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10)\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print('train loss: ', loss)\n",
    "print('train accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# 数据预处理\n",
    "path = r\"./data/siping/4g/siping_4g.csv\"\n",
    "\n",
    "# 将MR数据构建为7*4的矩阵\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "matrix = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(row) # 输出每行的索引值\n",
    "    for i in range(7):\n",
    "        matrix.append([i+1,\n",
    "                       row['AsuLevel_' + str(i+1)],\n",
    "                       row['SignalLevel_' + str(i+1)],\n",
    "                       row['Dbm_' + str(i+1)]]) # 新数据集中不存在RSSI，使用Dbm(代功率的绝对值)\n",
    "    print(matrix)\n",
    "    break\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def preprocess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    # 对经纬度进行归一化的处理\n",
    "    print(data.head(1))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data[['Longitude', 'Latitude']].values)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "def compute_time_interval(timestamp1, timestamp2):\n",
    "    dateArray1 = datetime.datetime.utcfromtimestamp(timestamp1 / 1000)\n",
    "    dateArray2 = datetime.datetime.utcfromtimestamp(timestamp2 / 1000)\n",
    "    # otherStyleTime = dateArray1.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return float((dateArray2 - dateArray1).seconds)\n",
    "\n",
    "def distance(true_pt, pred_pt):\n",
    "    lat1 = float(true_pt[1])\n",
    "    lng1 = float(true_pt[0])\n",
    "    lat2 = float(pred_pt[1])\n",
    "    lng2 = float(pred_pt[0])\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    s = 2 * math.asin(math.sqrt(math.pow(math.sin(a / 2), 2) +\n",
    "                                math.cos(radLat1) * math.cos(radLat2) * math.pow(math.sin(b / 2), 2)))\n",
    "    s = s * 6378.137\n",
    "    s = round(s * 10000) / 10\n",
    "    return s\n",
    "\n",
    "def mode_dict(path):\n",
    "#     path = data_dict[drname]\n",
    "    data = pd.read_csv(path)\n",
    "    trajs = data.groupby([\"TrajID\"])\n",
    "    m_d = {}\n",
    "    m_d[0] = []\n",
    "    m_d[1] = []\n",
    "    m_d[2] = []\n",
    "    for trajid, traj in trajs:\n",
    "        md = list(traj['mode'])\n",
    "        loc = traj[['Longitude', 'Latitude']].values\n",
    "        tl = list(traj['MRTime'])\n",
    "        for j in range(1, traj.shape[0]):\n",
    "            if j > 0:\n",
    "                delta_t = compute_time_interval(tl[j - 1], tl[j])\n",
    "                delta_s = distance(loc[j - 1, :], loc[j, :])\n",
    "                m = int(md[j])\n",
    "                if delta_t > 0:\n",
    "                    m_d[m].append(delta_s / delta_t)\n",
    "\n",
    "    return m_d\n",
    "\n",
    "print(mode_dict(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
